# Cookie

# 쿠키가 필요한 이유

http는 상태가 없다(stateless). === 이번 요청을 보내면 다음 요청에서 기억을 못한다.

헤더 중 하나(Cookie)를 트릭처럼 사용해서 정보를 기억하게 한다.

# URL에 따른 쿠키

상위 도메인에 설정하면 서브 도메인에서 사용할 수 있다.

→ kakao.com 쿠키 shop.kakao.com 사용 가능, 반대는 안됨.

패스도 같아야 한다.

→ kakao.com/api 의 쿠키는 kakao.com/api/user 에서 사용 가능하지만 kakao.com/app 에서는 사용할 수 없다.

# 쿠키 옵션

```tsx
const http = require('http');
const server = http.createServer((req, res) => {
  res.writeHead(200, {
    // 한글 사용 X, ASCII
    // HttpOnly를 해야 document.cookie로 접근하지 못한다.
    // 'Set-Cookie': 'test=TEST;',
    // 'Set-Cookie': 'test=TEST; HttpOnly;',
    // 'Set-Cookie': 'cookie-type=volatile; Max-Age=5',
    'Set-Cookie': 'samesite-none=true; Max-Age=10; SameSite=None',
  });
  res.end('ok');
});
server.listen(8080, () => {
  console.log('8080 포트에서 대기 중...');
})
```

참고로 쿠키는 한번 설정 되면 만료되기 전까지 매 요청마다 전송된다. 데이터(또는 네트워크 대역폭) 낭비이므로 꼭 필요한 것만 넣어야한다.

httpOnly - 자바스크립트에서 가져갈 수 있는가?? 못가져가게 해야함.

document.cookie로 접근 가능하다.

secure: https에서 작동

samesite

- none(secure(https) 일때만) - 남의 사이트 쿠키도 사용할 수 있다.
- Lax - 남의 사이트 쿠키를 사용할 순 없지만, 링크 클릭시 예외적으로 허용해주겠다.
- Strict - 해당 도메인에서만 쿠키를 건드림

# HTTP/2, HTTP3

# HTTP/1.1

text 기반(애초에 HTTP가 Hypertext Transfer Porotocol) - 즉 처음에 현재처럼 멀티미디어가 이렇게 많이 왔다갔다 할지 몰랐다.

3way handshake 비효율 - 요청에 대한 응답을 보내면 그 다음 요청을 할 때 또 3way handshake

→ 1.1 에서 connection: keep-alive

pipelining - 요청만 연달아 보내고 응답을 순차적으로 받는다.

→ 사실 구현이 어려워 실패했다. HOL 블록킹 현상.. TCP의 특성상 반드시 순서대로 받아야한다. 

→ 크롬, 사파리, 파폭 등 모든 브라우저가 도입을 포기했다.

여러 커넥션 제한(6~8개)

# HTTP/2.0

구글이 만든 SPDY가 표준이 돼 HTTP/2.0가 됐다.

구글은 주로 인터넷 세상에서 요청, 응답으로 인한 컨텐츠가 많고 그로 인한 수익 모델이 많기 때문에, HTTP의 비효율성으로 인한 낭비가 심하다. 그래서 선두해서 개발하는 경우가 많다. 트래픽 비용을 줄이기 위해서. 사실 결국 구글의 사적 이익을 위한 일이다.

## text 기반이 아닌 binary 기반이다(010101…).

→ 이로 인해 와이어 샤크같은 분석 도구를 써도 분석이 어려워졌다. 사람보단 컴퓨터가 이해하기 쉬운 방향으로 트레이드 오프.

## 스트림

하나의 커넥션에 여러 스트림이 있다. 즉 커넥션을 하나 맺어도 동시에 여러개의 요청을 보낼수 있다. 또한 스트림간 우선순위를 지정 가능하다.

## 헤더 압축

서버 푸시 → index.html 만 요청했느데 그 안에 필요한 link, script를 서버에서 그냥 보내준다. 그래서 클라이언트에서 요청 전에 리소스를 가져버리기 때문에 다시 요청할 필요가 없다. 다만 이건 서버에서 코딩해줘야 한다.

## HTTPS가 필수

정확히는 HTTP/2.0에서 HTTPS는 필수가 아니나, 브라우저 실제 구현에서는 HTTPS 없이 HTTP/2.0을 사용하는 것이 불가능하다.

# HTTP/3.0

이것 또한 구글이 개발한 것.

## UDP 프로토콜 사용

TCP의 비효율 성능을 극복하기 위함

TCP는 패킷 손실이 있을수 있는데 이럴때 HTTP/2.0의 성능이 매우매우 안좋아진다.

## QUIC

구글이 개발.

TLS1.3을 따른다.

이것 또한 HTTP/2.0을 따른다.

UDP이기 때문에 동영상 서비스에서 속도가 빠름

## 0RTT가능(zero round)

보안 위협 존재)

3way handshake를 극복하기 위한 방안

HTTPS 보안까지 3wayhandshake를 2번 하면 총 3번의 트랜잭션(요청, 응답)이 생기는데 이를 3 round tree 라 한다.

사실 없어버리면 reply attack에 취약하기 때문에 1번 왔다갔다 해야한다.(1RTT)

안전한 환경에서는 정말로 0번 가능하다.

# OSI 7계층에서는?

## HTTP1.1

전송 계층 - TCP

세션 계층 - HTTPS

응용 계층 - HTTP

## HTTP/2.0

L4~L7까지 전체적으로 HTTP2가 걸쳐져 있다.

왜냐면 프레임 바이너리(전송 계층) 개념을 가지고 있고 위에서 말했듯 HTTPS 개념을 포함해야 한다.

## HTTP/3.0

전송 계층 - UDP

L4, L5(전송, 세션) - QUIC

응용 - HTTP3은 따로 분리됐다.

QUIC 프로토콜은 꼭 HTTP로 쓰는게 아니라 HTTP3 말고 다른 프로토콜도 돌릴수 있다. 즉 범용적으로 사용할 수 있다.

# 10. HTTP/2.0

1997년 HTTP/1.1이 표준이 된 이후 HTTP/2.0에 대한 초안 작성이 진행되었고, 동시에 웹 기술이 많이 성숙 되었다. HTTP/2.0은 여러 초안이 검토 되었고 그 중 구글의 SPDY 프로토콜이 draft로 채택 되었다. 그리고 2015년 HTTP/2.0 스펙이 공게 되었다. 이 책은 2013년 11월 draft된 기점으로 설명하고 있다.

# 10.1. HTTP/2.0의 등장 배경

HTTP/1.1의 메세지 포맷은 성능 보단 단순성, 접근성에 주안점을 두고 개발 되었다. 특히, 응답을 받아야만 그 다음 요청을 보낼 수 있기 때문에 심각한 회전 지연(latency)를 피할 수 없었다. 이 문제를 피하려 병렬 커넥션을 도입하였지만 근본적인 해결책은 되지 못했다.

성능 개선을 위한 여러 아이디어들이 제가 됐고, 그 중 구글의 SPDY를 기초로 HTTP/2.0이 설계되었다.

# 10.2. 개요

HTTP/2.0도 TCP 커넥션 위에서 동작한다. 기존에 요청과 응답을 위해 다수의 커넥션을 사용했다면, HTTP/2.0에서는 하나의 커넥션에 여러 스트림을 사용한다. 이 스트림은 요청과 응답의 쌍으로 되어 있기 때문에 동시에 여러 요청을 보내고 받을 수 있게 되었다. 그 외에 흐름 제어, 우선순위 부여, 서버 푸시 등이 추가되었다.

서버 푸쉬는 클라이언트가 명확히 요청을 하지 않았어도 서버가 능동적으로 클라이언트에게 데이터를 보낼 수 있게 한다.

HTTP/2.0은 기본적으로 HTTP/1.1과 호환 된다. 404 status나 Content-Length 등의 개념은 호환 된다. 다만 그것을 표현하는 방식이 조금 바뀌었다.

Content-Length 헤더의 이름은 ‘:content-length’로, status는 ‘:status’ 헤더로 표현한다.

# 10.3. HTTP/1.1과의 차이점

프레임의 구조(책과 아래 구조가 다른데 책 출판 년도가 HTTP/2.0의 공식 발표 년도(2015년)보다 빨라서 그런거 같다.)([명세서 링크](https://httpwg.org/specs/rfc7540.html#FramingLayer))

```tsx
+-----------------------------------------------+
|                 Length (24)                   |
+---------------+---------------+---------------+
|   Type (8)    |   Flags (8)   |
+-+-------------+---------------+-------------------------------+
|R|                 Stream Identifier (31)                      |
+=+=============================================================+
|                   Frame Payload (0...)                      ...
+---------------------------------------------------------------+
```

Length: 페이로드의 길이를 나타내는 24비트 정수로, 프레임 헤더는 포함되지 않음.

Type: 프레임의 종류, 타입이 명확하지 않으면 무시될 수 있다.

Flags: 8비트로 되어 있고, 타입 마다 각 비트가 의미하는 것이 다르다.

R: 예약된 1비트로 반드시 0(unset)여야 하고, 받는 쪽은 무시.

Stream Identifier: 한 커넥션 안에서 스트림을 식별하는 값, 특히 0은 커넥션 전체와 연관된 프레임을 의미.

HTTP/2.0에서 스트림의 타입은 DATA, HEADERS, PRIORITY, RST_STREAM, SETTINGS, PUSH_PROMISE, PING, GOAWAY, WINDOW_UPDATE, CONTINUATION이 있다.

## 10.3.2. 스트림과 멀티플렉싱

스트림은 HTTP/2.0 커넥션을 통해 클라이언트와 서버 사이에 교환되는 프레임들의 독립된 양방향 시퀀스다. 스트림은 한 쌍의 요청과 응답으로 되어 있고, 응답이 되면 스트림이 닫힌다. 하나의 커넥션에서는 다수의 스트림을 동시에 사용하기 때문에 식별자를 만들었다.

스트림의 식별자에는 몇가지 규칙이 있다. 스트림은 클라이언트든 서버든 요청하는 쪽에서 만들어 낸다. 이때 클라이언트가 만든 식별자는 홀수이고 서버가 만든 스트림은 짝수여야 한다. 또 새로 만들어지는 스트림은 이전에 만들어졌거나 예약된 스트림의 식별자보다 커야 한다. 이 규칙을 어기게 되면 PROTOCOL_ERROR를 마주할 것이다.

한 번 사용한 스트림은 다시 사용할 수 없으며, 사용할 수 있는 식별자 값은 고갈될 수 있는데, 그 때는 커넥션을 다시 만들면 된다. (스트림 식별자는 같은 커넥션 안에서만 식별한다.)

## 10.3.3. 헤더 압축

HTTP/1.1 시절에 헤더는 아무런 압축 없이 그대로 전송되었다. 예전과 다르게 하나의 웹 페이지는 수백개의 리소스를 사용하는데 이때마다 헤더의 크기가 문제가 되었다. 매 요청마다 헤더가 필요하기 때문이다. 이를 개선하기 위해 HTTP/2.0에서는 헤더를 압축하여 전송한다. ([HPACK 명세 참고 링크](https://datatracker.ietf.org/doc/html/rfc7541))

## 10.3.4. 서버 푸시

HTTP/2.0은 요청을 하나만 보내도 응답으로 여러 개의 리소스를 보낼 수 있게 한다. 기존에 서버에서 HTML을 내려주면 클라이언트에서 받아서 필요한 리소스를 재 요청 했는데, 이런 지연을 줄여준다. 서버는 클라이언트가 필요로 하지만 요청하지 않은 리소스를 사전에 푸쉬를 통해 전송할수 있다.

서버 푸시를 사용하려면 서버가 먼저 클라이언트에게 PUSH_PROMISE 프레임을 보내서 알려야 한다.  또 서버 푸시를 종료하기 위해서는 클라이언트에서 RST_STREAM 프레임을 보내면 된다. 서버에서 푸시를 종료하려면 SETTINGS_ENABLE_PUSH을 0으로 하며 된다.

PUSH_PROMISE 라고 부르며 이를 통해 서버가 전송한 리소스에 대해선 클라이언트는 요청을 하지 않는다.

# **10.4 알려진 보안 이슈**

## **10.4.1 중개자 캡슐화 공격**

HTTP/2.0 중개자(프락시)가 HTTP/1.1 로 변환할 때 문제가 될 여지가 있다. HTTP/2.0은 헤더 필드를 이름과 같은 바이너리 값으로 인코딩하게 되는데 이때 줄바꿈 문자조차 허용된다. 이는 문제의 소지가 될 수 있다.

다양히 HTTP/1.1 → HTTP/2.0 인 상황에서는 이런 문제가 발생하지 않는다 한다.

## **10.4.2 긴 커넥션 유지로 인한 개인정보 누출 우려**

커넥션을 오래 사용하기 때문에 개인 정보를 악용할 여지가 높아진다.

# 11. 클라이언트 식별과 쿠키

서버에서 클라이언트를 식별하는데 사용하는 기술에 대한 주제를 다룬다.

# **11.1 개별 접촉**

HTTP는 익명으로 사용하며 상태가 없고 요청과 응답으로 통신하는 프로토콜이다.

모든 사용자에게 같은 페이지를 보여주는 것이 아닌, 개인을 위한 페이지도 제공해줄 필요가 있다. (쇼핑몰의 주문내역, 장바구니 등)

그러기 위해선 사용자를 식별할 기술이 필요한데, 초기 웹 사이트 설계자들은 아래와 같은 기술을 개발 했다.

- 사용자 식별 관련 정보를 전달하는 HTTP 헤더들
- 클라이언트 IP 주소 추적으로 알아낸 IP 주소로 사용자를 식별
- 사용자 로그인 인증을 통한 사용자 식별
- URL에 식별자를 포함하는 기술인 뚱뚱한 URL
- 식별 정보를 지속해서 유지하는 강력하면서도 효율적인 기술인 쿠키

# ****11.2 HTTP 헤더****

| 헤더 이름 | 헤더 타입 | 설명 |
| --- | --- | --- |
| From | 요청 | 사용자의 이메일 주소 |
| User-Agent | 요청 | 사용자의 브라우저 |
| Referer | 요청 | 사용자가 현재 링크를 타고 온 근원 페이지 |
| Authorization | 요청 | 사용자 이름과 비밀번호 |
| Client-IP | 확장(요청) | 클라이언트의 IP 주소 |
| X-Forwarded-For | 확장(요청) | 클라이언트의 IP 주소 |
| Cookie | 확장(요청) | 서버가 생성한 ID 라벨 |

From 헤더는 사용자 자신의 이메일을 입력하는 것인데, 스팸에 악용할 수 있어서, 이제는 보내지 않는다. 대신 봇에서는 관리자의 Email을 보내는데 사용한다.

User-Agent는 사용자를 특정할 수 없지만 매우 중요한 헤더다. 사용자가 사용하는 브라우저의 정보를 나타내기 때문에 사용자 환경에 맞는 문서를 줄 수 있다.

```tsx
> window.navigator.userAgent
'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'
```

Referer 헤더는 사용자의 성향을 추측할 수 있다. 티스토리를 하면 유입경로라고 해서 어디에서 링크를 타고 왔는지 알 수 있다. referer에 롤 사이트에서 오면 방금까지 롤을 하다가 온 것일 수 있다.

# 11.3. 클라이언트 IP 주소

IP를 개인 식별에 사용하려고 했지만, IP 주소는 사용자가 아닌 디바이스를 가리키며, 인터넷 서비스 제공자(ISP)는 동적으로 IP를 할당하는 문제가 있다. 또한 보안 강화와 부족한 주소를 관리하기 위해 많은 사용자가 네트워크 주소 변환(NAT) 방화벽을 사용할 때 실제 IP 주소가 가려진다.

즉 IP 고갈 문제에 맞물려 하나의 IP를 여러 사용자가 사용할 수 있어서 식별하기에는 맞지 않다.

# ****11.4 사용자 로그인****

HTTP는 WWW-Authenticate, Authorization 헤더를 사용해 사용자를 식별하는 체계를 가지고 있다.

![스크린샷 2023-05-30 오후 7.03.47.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3f2f121a-8a53-475a-a81c-7ee8c6860c4e/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.03.47.png)

사용자는 한 번 로그인하면 알아서 요청할 때마다 헤더에 식별 토큰을 담에 보낼수 있다.

<aside>
💡 OAuth(소셜 로그인)
책에는 없지만 근래에는 OAuth를 사용 한다. 대중에 인지도가 있는 서비스(google, facebook, github, kakao, naver)등에서 자체 로그인 검증 시스템을 다른 도메인이나 서비스에서도 사용할 수 있게 하는 것이다. 예를들어 google에 로그인 계정으로 같이 개인이 만든 서비스에서도 로그인을 할 수 있는 것이다. OAuth가 없을 때는 내가 이 사이트에는 어떤 아이디로 가입을 했지? 하는 고민을 했었는데, 말끔히 사라졌다. 개인적으로 자체 로그인 시스템을 만들 필요는 더이상 없는 것 같다. (물론 OAuth를 사용하고 자체 회원 가입 정보를 저장한다 하더라도 아이디와 비밀번호를 입력받게 할 필요가 없다.)

</aside>

<aside>
💡 비밀번호 없이 로그인
Medium, Slack은 사용자의 이메일로 소위 ‘매직 링크’라는 것을 보내 비밀번호를 입력하지 않고도 인증 및 로그인할 수 있게 한다.

</aside>

<aside>
💡 싱글 사이온(SSO)
대규모 회사에서 주로 사용하는 것으로, Okta와 같은 서비스를 사용해 각기 다른 서비스에 고유한 자격 증명을 발급하고 중앙에서 사용자 인증을 처리한다. SOO에 한 번 로그인하면 이와 연결된 웹 사이트에서는 다시 로그인할 필요가 없다.

</aside>

# ****11.5 뚱뚱한 URL****

어떤 웹사이트는 URL에 개인 식별 값을 포함하는 경우가 있었는데, 더이상 이런 방법을 고려하지 않는다.

단점으로는 너무 긴 URL, 공유하지 못하는 URL, 캐시 사용 불가(URL이 달라지기 때문에), 서버 부하 가중(URL이 달라져 HTML 페이지를 다시 그려야 함), 세션 간 지속성 부재(URL 북마킹하기 힘듦), 이탈(다른 URL로 갔을때 그 전 URL이 없다면 다신 같은 정보를 볼 수 없음)이 있다.

# ****11.6 쿠키****

쿠키는 사용자를 식별하고 세션을 유지하는 방식 중 가장 널리 사용하는 방식이다. 근래에는 JWT(Json Web Token)이라고 쿠키를 확용한 인증 방법이 가장 많이 사용된다.

쿠키는 넷스케이프가 최초로 개발했으며 캐시와 충돌할 수 있어서 대부분의 캐시나 브라우저는 쿠키에 있는 내용물은 캐싱하지 않는다.

## **11.6.1 쿠키의 타입**

쿠키는 크게 세션 쿠키와 지속 쿠키가 있다. 세션 쿠키의 경우 브라우저 창이 닫히면 사라지지만, 지속 쿠키는 디스크에 저장 돼 컴퓨터를 재시작 하더라도 남는다.

## **11.6.2 쿠키는 어떻게 동작하는가**

서버는 사용자를 식별하기 위해 접근하는 사용자에게 쿠키를 보낸다. 클라이언트는 이 쿠키를 명찰처럼 사용 가능하다.

## **11.6.3 쿠키 상자: 클라이언트측 상태**

쿠키의 기본적인 생각은 브라우저가 서버 관련 정보를 저장하고, 사용자가 해당 서버에 접근할 때마다 그 정보를 함께 전송하게 하는 것이다.

![스크린샷 2023-05-30 오후 7.45.23.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/25203b10-db3b-4f90-9d4d-665b61bdc846/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.45.23.png)

![크롬 구글 쿠키](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/40491239-a220-4f13-853f-2e39a0f3271c/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.48.14.png)

크롬 구글 쿠키

크롬은 Cookies라는 SQLite 파일에 쿠키를 저장하고, MS는 특정 디렉토리에 파일로 관리한다.

## **11.6.4 사이트마다 각기 다른 쿠키들**

쿠키는 특정 사이트에 종속된 값이다. 다른 도메인에서 쿠키에 접근하는 것은 보안에 문제가 생길 수 있다. 또 쿠키에는 직접적인 개인정보를 포함하는 것은 좋지 않다.

## **11.6.5 쿠키 구성요소**

현재 사용되는 쿠키는 Version 0 쿠키(넷스케이프 쿠키)다. 예전에 Version 1쿠키가 있었지만 지금은 폐기됬다.

## **11.6.6 Version 0 쿠키 (넷스케이프 쿠키)**

{name}={value} 형태로 {name}, {value}에는 큰따옴표, 세미콜론, 쉼표, 등로, 공백을 포함하지 않는 문자열이 와야 한다.

expires 형태는 GMT로 날짜간 구분자는 -(대시) 여야 한다.

domain 형태는 호스트 명으로만 사용할 수 있다. 상위 도메인에 설정하면 서브 도메인에서 사용할 수 있다.

(kakao.com 쿠키 shop.kakao.com 사용 가능, 반대는 안됨.)

path 는 말그대로 작성한 path에만 적용한다.

secure는 Optional한 속성으로 HTTP가 SSL 보안 연결을 사용할 때만 쿠키를 전송한다.

**http//Only**는 책에는 없지만 매우 중요한 값으로 사용자가 쿠키 값을 변경할 수 없도록 한다.

<aside>
💡 쿠키는 XSS 공격과 CSRF 공격 등에 취약하기 때문에 HttpOnly 옵션을 켜두고, 쿠키를 사용하는 요청은 서버 단에서 검증하는 로직을 꼭 마련해두는 것이 좋다.

</aside>

```tsx
// HTTP 응답
Set-Cookie: name=value [; expires=date] [; path=path] [; domain=domain] [; secure]

// HTTP 요청
Cookie: name1=value1 [; name2=value2] ...
```

만약 아래처럼 expires나 max-age를 넣지 않으면 세션 쿠키로 작동해 브라우저 창이 닫히면 사라진다.

```tsx
Set-Cookie: sessionid=38afes7a8; HttpOnly; Path=/
Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly
```

## 11.6.7. Version1 (RFC 2965) 쿠키

폐기 됐는데 도움 될 만한 내용도 없다.

## **11.6.8 쿠키와 세션 추적**

쿠키를 사용하여 사용자 식별을 할 수 있으니 연속적인 트랜잭션이 가능하다.

![스크린샷 2023-05-30 오후 7.58.07.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8af160ea-dd50-49f3-843f-8458e90fcf8d/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_7.58.07.png)

## **11.6.9 쿠키와 캐싱**

1. 캐시되지 말아야할 문서가 있다면 표시하라.
2. Set-Cookie 헤더를 캐시하는 것에 유의하라
3. Cookie 헤더를 가지고 있는 요청을 주의하라

## **11.6.10 쿠키, 보안 그리고 개인정보**

지속 쿠키와 referer 헤더를 사용하면 개인 정보를 너무 많이 알아낼 수 있다는 보안상의 문제가 있다.

# 12. 인증

웹에서 사용자 인증은 기본적인 절차라고 할 수 있다. HTTP는 자체적인 인증 관련 기능을 제공하는데, 그 중 HTTP의 기본 인증에 대해 알아보자.

# 12. 1. 인증

인증은 자신이 누구인지를 증명하는 것이다. 그러나 완벽한 인증은 없다.(감찰, 탈취, 위조에 대한 위험 때문에 이런 설명을 붙인거 같다.)

## **12.1.1 HTTP의 인증요구/응답 프레임워크**

![스크린샷 2023-05-30 오후 8.06.16.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/38f7b63f-4137-476c-af2c-fdfa15906b79/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_8.06.16.png)

## **12.1.2 인증 프로토콜과 헤더**

![스크린샷 2023-05-30 오후 8.07.44.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d5f29843-ba09-4f98-9dd5-fd2383a50ead/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2023-05-30_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_8.07.44.png)

(a) 인증 없이 요청을 보냄

(b) 인증이 필요하다는 401 status와 WWW-Autenticate 헤더를 보냄. 여기서 realm은 지시자

(c) 인증을 시도함. Authorization 헤더에 인증 정보를 포함하여 보냄

(d) 인증 성공(어떤 인증 알고리즘은 AuthentiationInfo에 인증 세션에 관한 추가 정보를 지술해 응답한다)

## **12.1.3 보안 영역**

위에서 WWW-Autenticate헤더에 realm을 사용 하는 것을 봤다. 예를들어 웹 서버에서 보안 영역을 family, coporation(사용자 권한) 등으로 여러개를 둘 수 있기 때문에 보안 영역을 지시자에 함께 보낸다.

# **12.2 기본 인증**

기본 인증은 널리 알려진 HTTP 인증규약이다. 다만 보안적으로는 취약한 형태다.

## **12.2.1 기본 인증의 예**

(a) 사용자가 어떤 리소스를 요청

(b) 서버는 인증 정보가 없는 사용자에게 WWW-Authenticate 헤더와 함께 401 응답

(c) 사용자는 인증 정보를 base-64로 인코딩해서 Authorization 헤더에 담아 보낸다.

(d) 서버는 Authorization 헤더에 있는 값을 디코딩한 후 값을 검사 한다. 정상적으로 인증을 마치면 200을 보낸다.

## **12.2.2 Base-64 사용자 이름/비밀번호 인코딩**

https://www.base64encode.net/ 에서 직접 인코딩 디코딩을 할 수 있다. 기억할 것은 인코딩과 디코딩은 매우 쉽기 때문에 노출된다면 언제든 원래의 값을 가져올 수 있기 때문에 암호화 됐다고 할 수 없다.

## **12.2.3 프락시 인증**

프락시 서버에서 인증을 처리할 수 있다.

## **12.3 기본 인증의 보안 결함**

기본 인증은 보안에는 취약하다. 사실상 보안을 하지 않은 것과 다름 없다. 그렇게 때문에 SSL 같은 암호 기술이 동반되야 한다. 다음 보안 결함을 살펴보자.

1. 기본 인증은 쉽게 디코딩 된다.
2. 메시지가 도중에 탈취되여 재전송 공격을 당할 수 있다.
3. 사용자는 아이디와 비밀번호를 같은 것을 사용하는 경향이 있기 때문에, 손쉽게 뚫린 비밀번호도 다른 사이트에서 사용될 여지가 있다.
4. 프락시 같은 중개자가 개입될 때 기본인증이 정상적으로 동작하지 않을 수 있다.
5. 기본 인증은 가짜 서버에 취약하다.